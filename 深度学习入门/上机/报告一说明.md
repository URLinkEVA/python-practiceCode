代码实现基于pytorch框架，主要分为构造数据集、训练、测试、网络建模四个部分。
# 构造数据集
即get_dataloader()：由于使用的是经典的MNIST数据集，故直接使用pytorch框架下提供的接口，首先创建MNIST数据集对象，再用dataloader包装。这里的batch_size设为64，并且打乱数据集。
# 训练
即train()：先将模型设为train模式，可以在前馈反馈过程中启用batch_norm和drop_out（虽然这边并没有用到）。然后通过for循环，获得每一个iteration中data_loader产生的一个batch的数据，并先将数据转移到模型所在的设备上（gpu/cpu）。这边需要先将优化器optimizer梯度置零，网络模型向前推理，然后由cross_entropy损失函数计算损失，并将梯度反向传播回到计算图上的每一个节点，最后使用优化器对模型参数进行更新。同时，在这边我设置每500个iteration打印一次日志。
# 测试
即test()：先将模型设为eval模式，可以在前馈过程中关闭batch_norm和drop_out。然后通过for循环，获得每一个iteration中data_loader产生的一个batch的数据，并先将数据转移到模型所在的设备上。将数据放入网络模型，向前推理，然后由cross_entropy损失函数计算损失，并且求和累计模型在训练集上总的loss。循环完毕之后计算其平均值，并打印日志作为输出结果。
# 网络建模
即class LinearNet(nn.Module)：先将batch_size=64、边长为28的图像拉成一维，形状为[784]，然后依次通过下述网络层。

|网络层|神经元个数|输入特征图|输出特征图|
|--|--|--|--|
|Affine|100	|[784]	|[100]|
|ReLU	-	|[100]	|[100]|
|Affine	|100|[100]	|[100]|
|ReLU	|-	|[100]	|[100]|
|Affine	|50	|[100]	|[50]|
|ReLU	|-	|[50]	|[50]|
|Affine|10	|[50]	|[10]|
|Softmax|	-|[10]  |[10]|
# 开始训练
在主函数中，编写主要的训练脚本，获取data_loader、设置gpu/cpu设备、实例化模型、实例化SGD优化器，学习率为0.01，然后训练10个epoch，每个epoch进行一次训练和测试，最终打印训练好的所有的网络参数。
